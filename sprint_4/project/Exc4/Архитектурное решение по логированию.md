# Архитектурное решение по логированию

- [Архитектурное решение по логированию](#архитектурное-решение-по-логированию)
    - [Анализ системы](#анализ-системы)
    - [Мотивация](#мотивация)
      - [Для технической команды](#для-технической-команды)
      - [Для бизнеса](#для-бизнеса)
      - [Приоритеты по системам (логирование/трейсинг в первую очередь)](#приоритеты-по-системам-логированиетрейсинг-в-первую-очередь)
    - [Предлагаемое решение](#предлагаемое-решение)
    - [Мероприятия для превращения системы сбора логов в систему анализа логов](#мероприятия-для-превращения-системы-сбора-логов-в-систему-анализа-логов)

### Анализ системы
Основные компоненты, из которых необходимо собирать логи:
1. Shop API
    - События: создание заказа, загрузка 3D-файла, проблемы при оплате (если есть), различные HTTP-запросы
    - Уровень INFO:
      - Создание заказа: логировать время, идентификатор покупателя (или сессии), номер заказа
      - Загрузка 3D-файла: логировать время, имя/ID файла, размер, результат (успех/ошибка)
2. CRM API
    - События: изменение статуса заказа (MANUFACTURING_APPROVED, CLOSED и тд), действия менеджеров
    - Уровень INFO:
      - Изменение статуса: кто (seller ID), какой заказ (order ID), старый и новый статус, время
3. MES API
   - События: запуск расчёта стоимости, присвоение оператора, завершение производства
   - Уровень INFO:
     - Расчёт стоимости: время старта, идентификатор заказа, предварительная сложность (кол-во полигонов), время окончания
     - Завершение производства: время, оператор, заказ
4. Messages Queue (RabbitMQ)
   - События: публикация сообщений (пришёл новый заказ/статус), потребление сообщений
    - Уровень INFO:
      - Публикация: идентификатор сообщения/заказа, тип события (ORDER_CREATED, STATUS_UPDATED)
      - Ошибки: (если в итоге сообщение уходит в Dead-letter-queue) — на уровне WARN/ERROR
5. 3D files storage (S3-based)
    - События: успех/неудача при чтении/записи 3D-файлов
    - Уровень INFO (или WARN при сбоях):
      - Загрузка файла: время операции, путь к файлу, результат
6. Базы данных (Shop DB, MES DB)
   - На уровне приложений (Shop/MES) уже будут логироваться SQL-ошибки (ERROR). При этом для аудита иногда включают INFO-уровень о критических транзакциях (например, insert в таблицу заказов)

**Другие уровни логирования:**
1. DEBUG: использовать при локальной разработке или в dev-окружении, чтобы видеть детальный стек. На production включается только при расследовании сложных инцидентов
2. WARN: логирование потенциальных проблемных ситуаций (переполнение очередей, медленные запросы)
3. ERROR: критические сбои (ex. не удалось сохранить заказ в БД)
4. INFO: основные бизнес-события (создание, изменение, удаление), ключевые транзакции


### Мотивация

#### Для технической команды
1. Ускоренный поиск корневых причин: Помимо трейсинга, логи помогают увидеть контекст бизнес-событий (Какой статус был изменён? Какие параметры заказа передавались?) и быстро сопоставить это с вызовами в трейсах
2. Обнаружение аномалий в потоках данных: Если вдруг CRM получает неожиданно много запросов на изменение статуса или MES не успевает завершать расчёты, логи на уровне INFO/WARN покажут картину активности
3. Сокращение MTTR: Инженеры смогут делать кросс-поиск по логам (в том же Kibana), сопоставляя конкретные заказы и даты

#### Для бизнеса
1. Повышение прозрачности: менеджеры (или support) могут быстро видеть, что происходило с заказом на каждом этапе (когда был изменён статус, были ли сбои)
2. Сокращение финансовых потерь: если вовремя выявляются и устраняются ошибки при оплате или расчёте 3D-модели, компания не теряет клиентов
3. Аналитика: на основе логов можно строить отчёты, смотреть, в какое время суток пики заказов, какие статусы чаще всего меняются с задержками

#### Приоритеты по системам (логирование/трейсинг в первую очередь)
1. Записи в базу данных (Shop DB) от CRM и Shop API
   - Почему именно база: Сейчас это главный узел, где сходятся операции из Shop и CRM, и именно здесь часто возникают долгие запросы и потенциальные блокировки
   - Что делаем:
     1. Логируем все критические записи/обновления заказов (INFO-уровень) с указанием order ID, user ID, времени выполнения
     2. Включаем slow query log или аналогичный механизм в самой СУБД, чтобы выявлять проблемные SQL-запросы и их планы выполнения
     3. Коррелируем логи с метриками БД (количество соединений, I/O wait, locks) для полной картины
2. Логи и трейсинг очереди RabbitMQ
    - Почему очередь: если сообщения копятся или залипают, CRM не успевает менять статусы заказов, а MES не получает вовремя данные
    - Что делаем:
      1. Логируем публикации и потребления (INFO/WARN) c ID заказа или события
      2. Отслеживаем количество сообщений в очереди, unacked сообщения, а также попадания в Dead Letter Exchange (DLX)
      3. При обнаружении массовых отбрасываний сообщений или резком росте очереди настраиваем алерты и углублённый анализ
3. MES API
   - Почему третьим: MES отвечает за сложные расчёты 3D-моделей, но на данный момент у компании сильнее болит база и очередь. Тем не менее при росте заказов MES тоже может стать узким местом
   - Что делаем:
     1. Логируем старт/завершение расчёта (INFO), фиксируя время, оператора, объём данных (количество полигонов)
     2. В трейсинге смотрим, не возникает ли захлебывание при массовых параллельных расчётах
     3. При выявлении чрезмерных задержек — рассматриваем горизонтальное масштабирование или оптимизацию алгоритмов

В итоге, сначала повышаем прозрачность логирования и трейсинга в базе данных (Shop DB), потом занимаемся RabbitMQ (сбор логов о количестве сообщений и unacked, интеграция с алертами), и только затем углублённо оптимизируем и логируем MES API. Такая расстановка приоритетов решает самую критичную проблему — бутылочное горлышко в базе — и обеспечивает стабильную асинхронную обработку заказов

### Предлагаемое решение

1. Внедрить в код библиотеки для логирования
    - Java (Shop API, CRM API) — Log4j или Logback (через Spring Boot)
    - C# (MES API) — Serilog или встроенный .NET ILogger
    - Консистентный формат логов (JSON или понятный текст). Важно иметь единое соглашение, чтобы все логи легко парсить

2. Поднять систему для сбора и хранения ELK-стек (Elasticsearch, Logstash, Kibana):
    1. Установить Filebeat (агент) на каждом сервере - рядом с Shop API, CRM API, MES API, RabbitMQ
    2. Развернуть Logstash для преобразования и маршрутизации в базу логов
    3. Хранить все логи в Elasticsearch
    4. Использовать Kibana для визуализации, анализа и простого дашборда по логам

3. Учесть аспекты безопасности
    - Защита чувствительных данных:
      - Убедиться, что в логи не пишутся пароли, токены, платёжные реквизиты
      - При необходимости использовать masking в Logstash, либо на уровне приложения
    - Разграничение доступа к логам
      - Логи содержат конфиденциальные бизнес-данные (номера заказов, имена клиентов). Доступ только у DevOps, SRE, продвинутых разработчиков и, возможно, менеджеров по поддержке с ограниченными привилегиями
      - Настроить аутентификацию/авторизацию в Kibana/Splunk

4. Определить политику хранения логов
    - Раздельные индексы (или отдельные индексы по сервисам/окружениям: `shop-api-*`, `crm-api-*`, `mes-api-*`)
    - Срок хранения: например, 30 дней для подробных логов, 90 дней для агрегированных. Зависит от бизнес-требований
    - Объём: оценить дневной объём логов (пиковые нагрузки + запас). При большом объёме настроить ротацию (ILM в Elastic)
    - Архивирование: возможно, старые логи уводить в S3 или Glacier (если требуется хранить на несколько лет)

Схема с учетом логирования (персиковый цвет) доступна по этой [ссылке](https://drive.google.com/file/d/1BLPll-I_Hu-SHWMi0AypVTMqXRWG7mZ8/view?usp=sharing)

### Мероприятия для превращения системы сбора логов в систему анализа логов

1. Алертинг
    - Настройка правил в Kibana:
      - Если за 1 минуту появилось > N сообщений об ошибках (ERROR) в MES API, формировать алерт
      - Если запросов на создание заказа резко стало слишком много (DDoS), алерт DevOps
    - Интеграция с Alert Manager

2. Поиск аномалий
    - Аномалии в количестве заказов:
      - Было 4 в секунду, стало 10 000. Это может быть атака или сбой/дубль при интеграции
    - Аномалии в статусах:
      - Заказ массово переходит в MANUFACTURING_COMPLETED без реального производства - тут логи могут подсказать источник фальшивого изменения статусов
    - Использовать ML/AI-модулей для поиска аномалий по паттернам логов

Таким образом мы не просто собираем всё подряд, но и выявляем аномалии, настраиваем алерты и получаем полноценную картину о работе всей системы.