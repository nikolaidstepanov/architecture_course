# Выбор и настройка мониторинга в системе

- [Выбор и настройка мониторинга в системе](#выбор-и-настройка-мониторинга-в-системе)
    - [Мотивация](#мотивация)
      - [Для технической команды:](#для-технической-команды)
      - [Для бизнеса:](#для-бизнеса)
    - [Выбор подхода к мониторингу](#выбор-подхода-к-мониторингу)
    - [Метрики](#метрики)
      - [CRM API](#crm-api)
      - [MES API](#mes-api)
      - [Shop API](#shop-api)
      - [Shop DB (и аналогично для CRM DB, MES DB)](#shop-db-и-аналогично-для-crm-db-mes-db)
      - [S3-based storage (3D-файлы)](#s3-based-storage-3d-файлы)
      - [RabbitMQ](#rabbitmq)
    - [План действий](#план-действий)
    - [Показатели насыщенности](#показатели-насыщенности)
      - [Shop API](#shop-api-1)
      - [CRM API](#crm-api-1)
      - [MES API](#mes-api-1)
      - [Shop DB](#shop-db)


### Мотивация

#### Для технической команды:
1. Ускорение процесса выявления и исправления ошибок:
   - Своевременный сбор метрик и логов даёт возможность быстро определить, в какой части системы (Shop, CRM, MES, RabbitMQ) возник сбой или деградация
   - Сокращается MTTR (Mean Time To Restore) и MTTA (Mean Time To Acknowledge): команда реагирует на проблемы быстрее, поскольку получает алерты и прозрачную картину в реальном времени
2. Повышение надёжности и стабильности системы
   - Мониторинг помогает находить корень проблемы, а не тушить пожары по следствиям. Например, если изначальная причина — перегрузка CPU при расчётах в MES, мониторинг это покажет, и команда может заняться оптимизацией алгоритмов или добавить нужные ресурсы
3. Проактивное выявление узких мест и повышение быстродействия
   - Анализ ключевых метрик (задержки, пропускная способность, загрузка ресурсов) позволяет заранее заметить растущую нагрузку
   - Это даёт время оптимизировать код, базу данных или саму инфраструктуру, прежде чем система захлебнётся под пиками запросов
4. Оптимизация производительности и более разумное распределение ресурсов
   - На основе показателей нагрузки (CPU, память, дисковая активность, сеть) команда может лучше планировать капасити
   - Мониторинг даёт конкретные цифры для аргументации перед руководством: «Нам нужна ещё одна реплика базы» или «Пора масштабировать MES-сервис на два инстанса»
5. Прозрачность для межкомандного взаимодействия
   - Когда каждый сервис (Shop, CRM, MES, RabbitMQ) имеет свою панель мониторинга и есть единый дашборд по всем компонентам, члены разных команд видят полную картину
   - Уходит больше времени на решение проблемы, а не на поиск виноватого — всё видно в метриках и логах
6. Основа для SLA, SLO и связанных бизнес-обязательств
   - Если компания предлагает B2B-интеграции (например, MES-API для партнёров), то для поддержания уровня сервиса нужны формальные метрики (доступность, время отклика, процент успешных расчётов)

#### Для бизнеса:
1. Повышаем стабильность и надёжность. Мониторинг помогает находить истинную причину проблем. Вместо того чтобы постоянно устранять последствия, мы сможем заранее распознавать слабые звенья и усиливать их
2. Ускоряем работу и обгоняем конкурентов. Благодаря анализу реальных метрик мы видим, где систему плющит, и устраняем эти bottleneck’и. Клиенты и партнёры замечают, что у нас всё работает быстрее и предсказуемее
3. Принимаем решения на основе фактов. Вместо предположений мы получаем реальные цифры по нагрузкам, времени отклика и пропускной способности. Это позволяет грамотно планировать бюджет и выстраивать оптимальную инфраструктуру
4. Подтверждаем наши обещания перед клиентами. Если мы заявляем, что 95% расчётов MES API проходят за X минут, то мониторинг нам доказывает, что эти цифры реальны, — бизнес-партнёры доверяют нашим отчётам, а не только словам


### Выбор подхода к мониторингу
1. **Shop API**
    - Подход: RED + Saturation
	- Почему: Shop API — это типичный REST-сервис с большим числом однотипных запросов (чтение каталога, оформление заказов). Метод RED хорошо отражает скорость и надёжность отклика, а отслеживание Saturation даёт ранний сигнал о перегрузке (например, рост очереди HTTP-тредов)
2. **CRM API**
    - Подход: Четыре золотых сигнала
    - Почему: CRM активно используется менеджерами, важна не только задержка (Latency) и процент ошибок, но и общий уровень загрузки (Saturation), когда много параллельных операций по заказам. Четыре золотых сигнала дают широкий охват для пользовательского веб-приложения
3. **MES API**
    - Подход: Четыре золотых сигнала + USE
    - Почему: помимо веб-запросов (где важны Latency, Traffic, Errors, Saturation), MES выполняет ресурсоёмкие расчёты 3D-моделей и может упираться в CPU/GPU. Метод USE (Utilization, Saturation, Errors) позволяет дополнительно отслеживать загрузку железа и очередей задач
4. **Shop DB, CRM DB, MES DB**
    - Подход: USE + метрики, специфичные для СУБД
    - Почему: в базах данных важен контроль утилизации ресурсов (CPU, IO, блокировки), насыщенности (очереди запросов) и ошибок (например, deadlock, replication lag). Плюс каждая СУБД (Postgres, MySQL и т. п.) имеет свои специфические метрики (slow queries, locks, connections)
5. **S3-based storage**
    - Подход: Четыре золотых сигнала
    - Почему: здесь также есть трафик (кол-во операций GET/PUT), задержка (время на загрузку/выгрузку), ошибки (4xx/5xx) и потенциальная насыщенность (пропускная способность сети)
6. **Rabbit**
	- Подход: RED + Saturation + метрики, специфичные для очередей
	- Почему: важно смотреть на Requests (операции чтения/записи), Errors (сбойные операции), Duration (время ответа) и длину очередей (Saturation)

### Метрики

#### CRM API
1. Response time (latency)
    - Зачем: измерять скорость отклика для продавцов, вовремя реагировать на замедления
   - Labels: endpoint (какой метод), status (2xx, 4xx, 5xx), чтобы локализовать проблему
2. RPS (Requests per second)
    - Зачем: понимать нагрузку и динамику трафика со стороны менеджеров, замечать всплески
    - Labels: endpoint (какие операции популярны)
3. HTTP Errors (4xx, 5xx)
    - Зачем: следить за качеством работы API, быстро замечать неполадки
    - Labels: endpoint, error_code (400, 404, 500 и тд)
4. Memory (RAM) utilisation
    - Зачем: не допустить OOM (Out Of Memory) при всплесках нагрузки
    - Labels: обычно достаточно общего usage по контейнеру/инстансу. По потребности можно детализировать (heap/non-heap), но не всегда обязательно
5. Number of simultaneous sessions
    - Зачем: отслеживать перегрузку по активным подключениям, видеть реальные пики одновременных пользователей
    - Labels: region или tenant (если есть многотенантность), но часто достаточно общей цифры
6. Number of processed messages from RabbitMQ (опционально)
    - Зачем: если CRM обрабатывает входящие сообщения (статусы заказов, нотификации), важно видеть реальное throughput
    - Labels: queue_name для понимания, какая именно очередь загружена

#### MES API
1. CPU %
    - Зачем: MES делает ресурсоёмкие расчёты (3D-модели). Нужен контроль, чтобы вовремя увеличить мощность
    - Labels: обычно общая утилизация; можно уточнять instance_id, если будет масштабирование
2. RPS
    - Зачем: видеть, сколько запросов поступает на расчёт и управление заказами
    - Labels: endpoint
3. Memory (RAM) utilisation
    - Зачем: сложные вычисления могут потреблять много памяти. Важно не превысить лимит
    - Labels: обычно достаточно общего usage
4. Response time (latency)
    - Зачем: следить за задержками в API-ответах. Если расчёты сильно замедляются, партнёры недовольны
    - Labels: endpoint (какой метод медленнее всех)
5. HTTP Errors (4xx, 5xx)
    - Зачем: сигнализирует о проблемах (таймауты, сбои во внешних вычислениях)
    - Labels: endpoint, error_code
6. Number of simultaneous sessions
    - Зачем: отслеживать, не захлёбывается ли API при массовых обращениях (особенно B2B-партнёры)
    - Labels: region или client_id (если есть ключи для B2B)
7. Kb transferred (received/sent)
    - Зачем: крупные 3D-файлы могут тянуть много трафика, полезно видеть объём
    - Labels: endpoint, method (upload/download)

#### Shop API
1. RPS
    - Зачем: динамика пользовательских запросов в онлайн-магазине.
    - Labels: endpoint (каталог, корзина, заказ)
2. Memory (RAM) utilisation
    - Зачем: следить, чтобы веб-приложение не вышло за ресурсы при нагрузке (акции, сезонные пики)
    - Labels: обычно общий usage
3. Response time (latency)
    - Зачем: покупатели сразу замечают медленную работу. Нужен контроль, чтобы не терять продажи
    - Labels: endpoint, http_method
4. HTTP Errors (4xx, 5xx)
    - Зачем: высокий процент ошибок сразу бьёт по доверию пользователей
    - Labels: endpoint, error_code
5. Number of simultaneous sessions
    - Зачем: понимать, сколько пользователей реально «в онлайне», может ли система справиться
    - Labels: можно указать region или device_type (мобильные vs. десктоп)

#### Shop DB (и аналогично для CRM DB, MES DB)
1. Number of connections
    - Зачем: контролировать pool-подключения, не упираемся ли в лимиты БД
    - Labels: instance_id, если несколько реплик
2. Memory utilisation
    - Зачем: БД может исчерпать память (особенно при крупных запросах, индексации)
    - Labels: общий usage по серверу
3. Disk utilisation
    - Зачем: чтение/запись, IO wait — важный показатель для производительности
    - Labels: разделы, volume_id, если нужна детализация
4. State (репликация, загруженность, locks)
    - Зачем: видеть, нет ли критических блокировок, lag репликаций
    - Labels: replica_id (если есть)
5. Slow queries, QPS, locks (дополнительно)
   -  Зачем: понять, не зависают ли сложные запросы, не накапливаются ли блокировки
  
#### S3-based storage (3D-файлы)
1. Size of S3 storage
    - Зачем: следить, как быстро растёт объём загруженных 3D-файлов, планировать затраты
    - Labels: bucket_name (если их несколько)
2. Number of requests (GET/PUT)
    - Зачем: видеть трафик загрузки/выгрузки
    - Labels: operation_type (GET vs PUT), status_code (2xx, 4xx, 5xx)
3. Latency (average upload/download time)
    - Зачем: крупные файлы могут замедлить весь процесс; важно вовремя увидеть рост задержек
    - Labels: operation_type (upload/download)

#### RabbitMQ
1. Number of messages in flight
    - Зачем: показывает, есть ли застрявшие сообщения, которые не обрабатываются быстро
    - Labels: queue_name
2. Dead-letter-exchange letters
    - Зачем: если много сообщений уходит в DLX, значит есть проблема в потребителях или контенте сообщений
    - Labels: queue_name, reason (при наличии)
3.	Publish/consume rate
    - Зачем: понять, не отстают ли консьюмеры от продьюсеров (Saturation)
    - Labels: queue_name

### План действий

1. Внедрить библиотеку/экспортёр метрик в каждый сервис
    - Чтобы Shop, CRM, MES и т. д. могли отдавать собственные метрики (RPS, Latency и пр.) в формате, совместимом с Prometheus
2. Установить агентов на серверах для системных метрик
   - Разместить, например, Node Exporter (или аналог) на каждом инстансе, чтобы собирать информацию о CPU, RAM, дисках и сети
3. Развернуть основной стек мониторинга
    - Поднять Prometheus (сервис сбора и хранения метрик), Grafana (визуализация), Alertmanager (управление алертами) и настроить Service Discovery (опционально, первое время можно настраивать вручную)
4. Настроить сбор данных от всех сервисов и БД
    - Указать Prometheus, откуда забирать метрики (URLs /metrics в микросервисах, экспортеры для Redis, RabbitMQ, PostgreSQL и тд)
5. Определить и настроить Retention (время хранения метрик)
    - В prometheus.yml указать, сколько исторических данных нужно держать, чтобы не захламлять диск и иметь достаточно истории для анализа
6. При необходимости использовать Push Gateway
    - Для кратковременных джоб (скриптов, cron-задач), которые не могут быть запулены Prometheus напрямую
7. Построить дашборды в Grafana
    - Для каждого сервиса (Shop, CRM, MES), баз данных и инфраструктуры — визуализировать ключевые метрики в удобном формате.
8. Определить пороги и настроить алертинг
    - Задать триггеры (Latency > X, Errors > Y) в Alertmanager, привязать к Slack, e-mail и тд, чтобы команда получала уведомления о критических инцидентах

### Показатели насыщенности

#### Shop API
1. **Очередь входящих HTTP-запросов**  
   - Порог: > 500 одновременно обрабатываемых запросов или > 90% заполненности thread pool
   - Почему: при большом числе конкурентных запросов растёт задержка и снижается UX, потенциально теряются продажи
   - Действия:
     - Автоматически увеличить количество инстансов (горизонтальное масштабирование)
     - Создать тикет DevOps с приоритетом high
     - Отправить уведомление в Slack/e-mail

2. **Загрузка CPU на инстансе Shop API**  
   - Порог: > 80% в течение 5 минут
   - Почему: длительная высокая загрузка процессора приводит к замедлению всей системы
   - Действия:
     - Создать тикет на анализ нагрузки
     - При повторении превышения — добавить инстанс или перейти на более мощный тип

#### CRM API
1. **Количество активных сессий менеджеров**  
   - Порог: > 100 одновременных пользователей, исходя из текущего thread pool и опыта команды
   - Почему: CRM может «захлёбываться» при резких всплесках активности, что влияет на работу продавцов
   - Действия:
     - Отправить алерт DevOps, запустить дополнительный инстанс CRM при необходимости
     - Предупредить команду о временных ограничениях/пиках

2. **Очередь сообщений в RabbitMQ для CRM**  
   - Порог: > 100 неотобранных сообщений подряд в течение 10 минут
   - Почему: если CRM не успевает забирать сообщения, возможны задержки обновления статусов заказов и несогласованность данных
   - Действия:
     - Отправить уведомление (Slack/e-mail) с указанием `queue_name`
     - Увеличить число CRM-консьюмеров или выяснить, что блокирует их обработку

#### MES API
1. **Очередь задач на расчёт 3D**  
   - Порог: > 20 активных долгих расчётов (каждый может занимать до 30 минут)
   - Почему: накапливающиеся длинные расчёты сильно увеличивают ETA для клиентов и партнёров
   - Действия:
     - Создать тикет DevOps с приоритетом high
     - Рассмотреть дополнительные инстансы или опции GPU
     - Уведомить менеджеров о потенциальной задержке заказов

2. **Утилизация CPU**
   - Порог: > 90% на протяжении 10 минут
   - Почему: MES может стать узким местом при непрерывном росте запросов и ресурсозатратных расчётах
   - Действия:  
     - Отправить алерт (Slack, e-mail)
     - При повторном превышении — добавить инстанс, масштабировать кластер или оптимизировать код

#### Shop DB
1. **Количество активных соединений**  
   - Порог: > 80% от максимально доступного пула (например, 80 из 100)
   - Почему: если пул исчерпан, новые подключения блокируются, увеличивается Latency и растёт риск 5xx ошибок
   - Действия:  
     - Создать тикет DBA
     - Возможное решение — увеличить пул временно, оптимизировать SQL-запросы

2. **Уровень I/O Wait**  
   - Порог: > 50% в течение 5 минут
   - Почему: высокая задержка дисковой подсистемы замедляет транзакции и может подтормозить Shop/CRM
   - Действия:
     - Алерт DevOps
     - Рассмотреть более быстрый тип диска, репликацию для чтения, либо перенос больших запросов на непиковое время