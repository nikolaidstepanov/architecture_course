# Планирование: анализ, идентификация проблем и поиск решений

- [Планирование: анализ, идентификация проблем и поиск решений](#планирование-анализ-идентификация-проблем-и-поиск-решений)
    - [Существующие и потенциальные проблемные места](#существующие-и-потенциальные-проблемные-места)
    - [Инициативы, которые необходимы для устранения нежелательных ситуаций](#инициативы-которые-необходимы-для-устранения-нежелательных-ситуаций)
    - [Целевая архитектура через полгода](#целевая-архитектура-через-полгода)
    - [FAQ](#faq)


### Существующие и потенциальные проблемные места
- Несогласованность данных о статусе заказа:
    - Каждый из трёх приложений (Shop, CRM, MES) частично владеет статусами и меняет их со своей стороны, при этом нет единого «источника истины»
    - Используется асинхронное взаимодействие через RabbitMQ, что может приводить к расхождениям статусов при сбоях или задержках обработки сообщений
- Задержки на стороне MES API:
    - Особенно при расчёте стоимости сложных 3D-моделей. Расчёт может занимать до 30 минут, при этом нагрузка растёт из месяца в месяц, а часть расчётов — явно CPU-bound
    - Важно понять:
      - Какие именно запросы к MES вызывают задержку: расчёт цены, получение списка заказов или и то, и другое?
      - Как распределяется нагрузка по времени суток — есть ли всплески, которые вызывают «затор»?
      - Есть ли какие-либо таймауты или ретраи, которые усугубляют ситуацию при больших объёмах?
- Недовольство операторов из-за неудобного UI в CRM и медленной загрузки страниц:
    - CRM-приложение долго подгружают заказы (даже после добавления фильтров и пагинации). Важно, чтобы операторы быстро видели новые заказы, ведь от этого зависит их вознаграждение
- Перегруженная база данных Shop
    - Shop DB служит одновременно для Shop API и CRM API, возникает конкуренция за ресурсы
    - Чтение и запись идут в один инстанс без репликации или разделения; при росте заказов эта проблема будет только усиливаться
- Проблемы с RabbitMQ при высоких пиковых нагрузках:
    - Нужна проверка настройки очередей, количества консьюмеров, механизма retry, чтобы сообщения не «зависали»
    - При обилии заказов от внешних партнёров (через MES API) очередь может переполняться, что увеличивает задержки
- Недостаточная автоматизация тестирования:
    - QA в основном ручной, что затягивает релизы и повышает риск пропустить критичные баги при быстром росте функционала
    - Нет постоянных нагрузочных тестов и интеграционных тестов на уровне всех сервисов
- Бюрократические задержки и ручные процессы в релизном цикле:
    - После мержа в dev-ветку всё деплоится автоматически, но на release и prod переносят вручную. При обнаружении багов высоких приоритетов релизы могут «застрять» на срок до месяца
- Отсутствие чётких SLA, SLI, SLO между сервисами:
    - Трудно аргументировать бизнесу потребность в ресурсах, когда нет формализованных показателей («MES должен давать ответ на расчёт цены за столько-то минут с вероятностью X%»)
    - Нет нужной прозрачности, чтобы вовремя обнаруживать узкие места

### Инициативы, которые необходимы для устранения нежелательных ситуаций
1. Реплицировать базу данных Shop
    - Уменьшить конкуренцию за ресурсы, вынеся чтение на реплику, а запись на основной инстанс
    - Рассмотреть подход CQRS
    - Проанализировать медленные SQL-запросы (slow query logs) и оптимизировать индексы, архитектуру таблиц, JOIN-ы
2. Добавить кеш в CRM (на уровне HTTP и на уровне сервера)
    -  Снизить нагрузку на базу и ускорить вывод списка заказов. Важно заранее продумать стратегию обновления/инвалидирования кеша, чтобы операторы видели актуальные статусы
3. Добавить автоматическую сортировку заказов по актуальной дате в CRM
    - Улучшить UX, чтобы операторы первыми видели новые или срочные заказы. Желательно делать сортировку на стороне бэкенда, не передавая клиенту избыточные объёмы данных
4. Повысить observability системы (мониторинг, логирование, трассировка)
    - Внедрить инструменты (Prometheus, Grafana, ELK/EFK, Jaeger/Zipkin/OpenTelemetry и тд) для сбора метрик, логов и распределённого трейсинга
    - Настроить алертинг, чтобы оперативно реагировать на задержки и сбои
    - Подумать о хайринге SRE (или выделить часть времени одного из текущих бэкенд-разработчиков) для оптимизации и внедрения SLA, SLI, SLO
5. Разработать Order Service или чёткую схему «владения» заказами
    - Чтобы было ясно, где хранится «истинный» статус заказа и кто в каком формате может его менять
    - Можно либо сделать единый сервис с собственной БД, либо настроить чёткую event-driven интеграцию между уже существующими базами
6. Добавить инстансы для API (Shop, CRM, MES) и балансировать нагрузку
    - Горизонтальное масштабирование позволит обслуживать растущий поток запросов от B2C и B2B клиентов
7. Добавить CPU ресурсы для MES API
    - В краткосрочной перспективе может дать существенный выигрыш
    - Дополнительно провести код-ревью алгоритмов расчёта, чтобы убедиться, что нет неоптимальных операций
    - Если задача расчёта цены слишком сложна, вынести её в отдельный «Pricing Service», который можно горизонтально масштабировать под увеличивающуюся нагрузку
8. Нанять ещё одного DevOps и перейти на Kubernetes
    - Позволит автоматизировать развёртывание, масштабирование и управление сервисами
    - Поможет при миграции на K8S, настройке кластеров, написанию Helm-чартов, обучению команды
9. Сделать для CRM отдельную базу или разделить процессы чтения и записи
    - Идея похожа на CQRS, где Shop DB остаётся «главной» для заказов (или наоборот), а CRM имеет свою БД для быстрой выборки, синхронизируясь через события или API
10.	Усовершенствовать CI/CD (автотесты, автоматический деплой в релиз)
    - Наладить автоматизацию тестирования (юнит-, интеграционные и E2E-тесты)
    - Сократить время релизов за счёт feature toggles и canary releases
11.	Добавить Backpressure для взаимодействия между API User и MES API
    - Использовать rate limiting, очереди, чтобы MES не «заваливался» при наплыве запросов с внешнего API
    - Настроить механизмы повторной доставки и отслеживания статусов расчёта
12.	Разделить API для операторов и для API User
    - Разграничить конечные точки и бизнес-логику, чтобы можно было независимо масштабировать эти части в MES
    - Улучшить производительность интерфейса операторов, не тянув лишние данные
13.	Усиление тестовой стратегии
    - Нанять QA-автоматизатора или выделить время текущего QA, чтобы покрыть ключевые сценарии автоматическими тестами
    - Настроить регулярные нагрузочные тесты (JMeter, Gatling, Locust), чтобы отслеживать деградацию производительности при росте заказов

### Целевая архитектура через полгода

Через полгода мы видим систему, способную стабильно обрабатывать растущий поток заказов и обеспечивать высокую скорость отклика.

За счёт репликации и оптимизации баз данных Shop и CRM снимаются узкие места на уровне чтения и записи, а дальнейшая контейнеризация и балансировка нагрузок позволяют гибко масштабировать сервисы. При этом прозрачность статусов заказа повышается благодаря единому подходу к хранению и изменению информации — каждый сервис (Shop, CRM, MES) либо взаимодействует с централизованным «Order Service», либо пользуется хорошо выстроенной схемой обмена событиями.

Важную роль играет повышение Observability: мы настраиваем системный мониторинг, распределённый трейсинг и централизованное логирование, чтобы отслеживать аномалии в реальном времени и оперативно реагировать на сбои. Это даёт чёткие SLA и SLO, которые нужны и для внутренних команд, и для B2B-партнёров.

В дополнение к этому, у нас ускоряются и становятся безопаснее релизы. Команда переходит на полноценный CI/CD с автотестами (юнит, интеграционные и E2E), что сокращает время обнаружения критических дефектов и позволяет выкатывать новые фичи без длительных задержек.

Наконец, UI для операторов и продавцов становится более удобным и быстрым — благодаря кешированию, оптимизированным запросам и продуманной архитектуре фронтенда.

Топ-3 приоритетные инициативы на ближайшие полгода:
1. Репликация БД и разгрузка Shop DB (включая возможное разделение CRM и Shop или внедрение CQRS-подхода)
2. Повышение Observability (мониторинг, трейсинг, централизованное логирование) для прозрачности процессов и быстрого реагирования на сбои
3. Добавление кеша в CRM и повышение быстродействия интерфейса (особенно для операторов, чтобы они оперативно видели новые заказы)


### FAQ
1. Какие метрики можно внедрить для мониторинга состояния системы?
- Основные (RED / 4 золотых сигнала): Requests (RPS), Errors, Duration/Latency, Saturation
- Системные: CPU/Memory/IO usage на каждом сервисе, длина очереди (RabbitMQ), число соединений и медленные запросы (Shop DB), объёмы S3
- Бизнес-метрики: количество активных заказов в день, среднее время расчёта цены в MES, процент успешно обработанных сообщений в CRM/MES

2. Какие техники логирования и трассировки помогут идентифицировать место потери заказов?
- Распределённый трейсинг (OpenTelemetry/Jaeger), чтобы виден был полный путь заказа (Shop -> CRM -> MES -> DB -> очередь)
- Корреляционные ID (orderId) в логах и сообщениях. Это даёт возможность находить разрывы цепочки в RabbitMQ или БД
- Централизованное логирование (ELK), где все сервисы пишут логи с единым полем orderId, упрощая поиск

3. Как можно разделить API для внутренних и внешних пользователей, чтобы контролировать внешнюю и внутреннюю нагрузку?
- Разделить конечные точки (например, /api/v1/internal vs /api/v1/external) или даже сделать разные микросервисы (Operator API, Public API)
- Отдельное масштабирование: внешние запросы часто идут массово (B2B), внутренние (операторы) критичны по SLA. Разделённые сервисы или ресурсы упрощают приоритеты и лимиты (rate limiting, QoS)

4. Какие риски возникают при совместном использовании одной базы магазином и CRM?
- Производительность: рост конкурирующих запросов (Shop и CRM) приводит к блокировкам и медленным ответам
- Нет single source of truth по статусам, если логика частично в CRM, частично в Shop
- Возможные deadlock’и при одновременно интенсивных операциях чтения/записи

5. Как процесс подсчёта стоимости заказов можно ускорить / сделать асинхронным?
- Выделить «Pricing Service» (микросервис) и обрабатывать расчёты в отдельной очереди: MES публикует задачу, сервис параллелит вычисления
- Горизонтально масштабировать сервис расчёта, добавляя CPU/GPU при пиках
- Кэширование типовых расчётов (если модели повторяются), но тогда важно зафиксировать методику поиска похожих моделей
- Асинхронность: пользователь/CRM не ждёт синхронно 30 минут, а получает результат через callback/ RabbitMQ-событие